# Fintech 招商银行数据科学比赛

### 任务介绍
* 任务类型：二分类预测
* 数据集：
    * train set：40000条数据
    * test_A set: 10000条数据（前10天）
    * test_B set: 12000条数据（后十天）
    * feature_explain: 数据说明
* 评价指标：ROC_AUC
* 分数计算：test_A * 0.3+ test_B * 0.7
* 尝试次数：每天三次

### Test A
4.29-5.9

特征说明仅仅说明了哪些特征是数值特征，哪些特征是类别特征，并没有说具体含义，说明此次比赛单纯就是拼模型的简单比赛

拿到数据的当天尝试使用了LightGBM单模就能够达到0.951 的AUC_Score

最终是使用了 XGBoost，LightGBM，Random Forest模型并使用逻辑回归Stacking，不过分数并没有明显的提升

### Test B
5.10-5.12

当我用原先训练好的模型提交上去发现auc仅有0.68

所以显然过拟合的问题严重，仅有3天的时间完成工作，剩余9-1=8次机会

于是我开始尝试限制树的深度；根据树特征重要性提取前1/3的特征进行训练；尝试其它Stacking融合的方式，结果有一定的提升（0.71）但无法有更好的突破

在最后一天我意识到数据的分布是不一致的，使用了对抗验证（Adversary Validation）方法,分别把数据集和测试集进行标记（label：是否属于测试集），然后建立模型训练，预测train_set中每一行的数据属于测试集的概率，对于预测值高的训练集，可以认为它有更接近test_set的特征，拥有更高的权重。

在实际模型进行训练时，将训练集属于测试机的概率作为交叉验证的权重进行训练 ，及时地early stop
模型又有了一定的提升，但AUC仅为0.74，此时最后三次机会也已经用完，我也黔驴技穷

### 总结

1. 先前缺乏数据竞赛的经验，对于验证集和训练集分布不同没有在短时间内找到有效办法的能力
2. 我看赛后开源的代码中，普遍流行的是使用对抗训练删除高于AUC的毒特征，而我的方法是给train_test的预测值作为权重，再用树减枝删除特征，因此性能有很大的差异
3. 没有及时进入交流群沟通，一直在单打独斗，其实群消息的讨论里有许多有价值的思路



### 文件说明

`EDA.ipynb` 查看特征分布，并建模预测对抗验证的权重

`dict.ipynb` 对数据进行预处理，对类别特征进行编码（one-hot编码和字典序编码两种）

`feature.ipynb`在完成test_b时删除了前一半的特征

`baseline_randomforest.py`  随机森林模型

`lgb_new.py`  LightGBM 模型

`xgb.py`  XGBoost 模型

`Stacking.ipynb` 模型融合